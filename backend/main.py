import os
import re
import sys
import logging
import json
import uuid
import time
import requests
from datetime import datetime
from typing import Optional, List, Any, Dict
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from dotenv import load_dotenv

# [ë¡œì»¬ ê°œë°œìš©] ìƒìœ„ í´ë”(.env)ì˜ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
# Dockerì—ì„œëŠ” env_fileë¡œ ì£¼ì…ë˜ì§€ë§Œ, ë¡œì»¬ ì‹¤í–‰ ì‹œ í•„ìš”í•©ë‹ˆë‹¤.
load_dotenv(dotenv_path="../.env")

# --- [Monkey Patching: í˜¸í™˜ì„± í•´ê²°] ---
import langchain_core.callbacks
import langchain_core.callbacks.base
import langchain_core.agents
import langchain_core.documents
import langchain_core.messages
import langchain_core.outputs

sys.modules["langchain.callbacks"] = langchain_core.callbacks
sys.modules["langchain.callbacks.base"] = langchain_core.callbacks.base
sys.modules["langchain.schema"] = langchain_core.messages 
sys.modules["langchain.schema.agent"] = langchain_core.agents
sys.modules["langchain.schema.document"] = langchain_core.documents

# [Langfuse & LangChain Integrations]
from langchain_core.messages import SystemMessage, HumanMessage
from langfuse.decorators import observe, langfuse_context
from langfuse.callback import CallbackHandler

# --- [Biomni Import] ---
from biomni.agent.a1 import A1

load_dotenv(dotenv_path="../.env")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("BiomniWeb")

app = FastAPI()

# 1. ì •ì  íŒŒì¼ ì„œë¹™ ì¶”ê°€ (ìƒì„±ëœ ì´ë¯¸ì§€/PDF ì ‘ê·¼ìš©)
# Docker volume ë§¤í•‘ì— ë§ì¶° ê²½ë¡œ ì„¤ì • (ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ê²½ë¡œ: /app/data)
if os.path.exists("/app/data"):
    app.mount("/data", StaticFiles(directory="/app/data"), name="data")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

agent: Optional[A1] = None

def initialize_agent():
    global agent
    logger.info("Initializing Biomni Agent...")
    try:
        # Docker í™˜ê²½ ë³€ìˆ˜ ìš°ì„ , ì—†ìœ¼ë©´ ë¡œì»¬ ê²½ë¡œ
        data_path = os.getenv("BIOMNI_DATA_PATH", "../biomni_data")
        agent = A1(path=data_path)
        logger.info("Biomni Agent initialized successfully.")
    except Exception as e:
        logger.error(f"Failed to initialize Biomni Agent: {e}")
        agent = None

initialize_agent()

class ChatRequest(BaseModel):
    message: str

# ì‘ë‹µ ëª¨ë¸ ì •ì˜ (ë¡œê·¸ í¬í•¨)
class ChatResponse(BaseModel):
    response: str
    logs: List[Any]  # Biomniì˜ response_log êµ¬ì¡°ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ì„¤ì •

@app.post("/api/chat", response_model=ChatResponse)
@observe(name="Biomni Chat Interaction")
async def chat_endpoint(request: ChatRequest):
    if not agent:
        # ì¬ì‹œë„ ë¡œì§ (í•„ìš”ì‹œ)
        initialize_agent()
        if not agent:
            raise HTTPException(status_code=500, detail="Agent not initialized")
    
    logger.info(f"Received request: {request.message}")
    
    try:
        # ... (ê¸°ì¡´ Monkey Patching ë¡œì§ ê·¸ëŒ€ë¡œ ìœ ì§€) ...
        # (original_stream, traced_stream ì •ì˜ ë¶€ë¶„)

        # agent.app.stream = traced_stream 
        
        # 4. ì—ì´ì „íŠ¸ ì‹¤í–‰
        langfuse_handler = langfuse_context.get_current_langchain_handler()
        response_log, response_content = agent.go(request.message, callbacks=[langfuse_handler])
        
        # agent.app.stream = original_stream
        
        # Langfuse ì—…ë°ì´íŠ¸
        langfuse_context.update_current_trace(
            output=str(response_content),
            metadata={"full_log_length": len(response_log)}
        )

        # ğŸŒŸ ë§¤ìš° ì¤‘ìš”: ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìˆ˜ì§‘ ì¤‘ì¸ ëª¨ë“  í•˜ìœ„ Spanë“¤ì„ ì„œë²„ë¡œ ê°•ì œ ì „ì†¡ ì™„ë£Œì‹œí‚µë‹ˆë‹¤.
        langfuse_context.flush()

        trace_id = langfuse_context.get_current_trace_id()
        
        # Langfuse ì„œë²„ì˜ DBì— í•˜ìœ„ Spanë“¤ì´ ì™„ì „íˆ ê¸°ë¡ë  ë•Œê¹Œì§€ ì•„ì£¼ ì ê¹(1~2ì´ˆ) ëŒ€ê¸°í•©ë‹ˆë‹¤.
        time.sleep(3) 
        
        langfuse_host = os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com").rstrip("/")
        public_key = os.getenv("LANGFUSE_PUBLIC_KEY")
        secret_key = os.getenv("LANGFUSE_SECRET_KEY")
        
        # Langfuse REST APIë¥¼ í˜¸ì¶œí•˜ì—¬ í•´ë‹¹ íŠ¸ë ˆì´ìŠ¤ì˜ 'ëª¨ë“  ì„¸ë¶€ ì •ë³´'ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤.
        api_url = f"{langfuse_host}/api/public/traces/{trace_id}"
        api_response = requests.get(api_url, auth=(public_key, secret_key))
        
        if api_response.status_code == 200:
            full_trace_data = api_response.json()
            
            base_log_dir = "/app/logs" # ë˜ëŠ” "/app/data/reasoning_dataset"
            
            # ==============================================================
            # 1. ì›ë³¸ ë°ì´í„° (Raw Data) ì €ì¥
            # ==============================================================
            raw_dir = os.path.join(base_log_dir, "raw")
            os.makedirs(raw_dir, exist_ok=True)
            
            raw_data = {
                "trace_id": trace_id,
                "timestamp": datetime.now().isoformat(),
                "instruction": request.message,
                "langfuse_full_trace": full_trace_data, 
                "response_log": response_log, # "type": "ai" ë°ì´í„°ë¥¼ í¬í•¨í•˜ëŠ” ì›ë³¸ ë¡œê·¸ ì „ì²´
                "final_answer": str(response_content)
            }
            
            raw_file_path = os.path.join(raw_dir, f"trace_{trace_id}.json")
            with open(raw_file_path, "w", encoding="utf-8") as f:
                json.dump(raw_data, f, ensure_ascii=False, indent=4)
                
            # ==============================================================
            # 2. íŒŒì¸íŠœë‹ìš© ì •ì œ ë°ì´í„° (Refined Data)
            # ==============================================================
            refined_dir = os.path.join(base_log_dir, "refined")
            os.makedirs(refined_dir, exist_ok=True)
            
            # [ì´ˆê°•ë ¥ íŒŒì„œ] ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ ë¡œê·¸ë¥¼ ë§ˆì£¼í•˜ë©´ ì ˆëŒ€ í›¼ì†í•˜ì§€ ì•Šê³  100% ê·¸ëŒ€ë¡œ í†µê³¼ì‹œí‚µë‹ˆë‹¤.
            def dump_msg(obj):
                # ğŸŒŸ [í•µì‹¬ ìˆ˜ì •] ì›ë³¸ì´ ë”•ì…”ë„ˆë¦¬ë©´ ê·¸ ì–´ë–¤ ì†ì„± ìœ ì‹¤ ì—†ì´ ê·¸ëŒ€ë¡œ ë°˜í™˜! (ì´ì „ ë²„ê·¸ ì›ì¸ í•´ê²°)
                if isinstance(obj, dict):
                    return dict(obj)
                    
                d = {}
                if hasattr(obj, "dict") and callable(obj.dict):
                    try: d.update(obj.dict())
                    except: pass
                elif hasattr(obj, "__dict__"):
                    try: d.update(vars(obj))
                    except: pass
                    
                for attr in ["id", "name", "type", "content", "tool_calls", "invalid_tool_calls", "response_metadata", "additional_kwargs", "usage_metadata"]:
                    if hasattr(obj, attr):
                        val = getattr(obj, attr)
                        if not callable(val):
                            d[attr] = val
                return d

            def extract_msgs(obj):
                extracted = []
                if isinstance(obj, (list, tuple)):
                    for item in obj:
                        extracted.extend(extract_msgs(item))
                elif isinstance(obj, dict):
                    m_type = obj.get("type")
                    # ë”•ì…”ë„ˆë¦¬ ìì²´ê°€ ë©”ì‹œì§€ì¸ ê²½ìš° í†µì§¸ë¡œ ì €ì¥
                    if isinstance(m_type, str) and m_type in ["ai", "tool", "ai_message", "tool_message"]:
                        extracted.append(dump_msg(obj))
                    else:
                        for k, v in obj.items():
                            extracted.extend(extract_msgs(v))
                elif hasattr(obj, "type") and hasattr(obj, "content") and not isinstance(obj, type):
                    extracted.append(dump_msg(obj))
                return extracted

            raw_msgs = extract_msgs(response_log)
            
            # AI / Tool ë©”ì‹œì§€ë§Œ ì¶”ë¦¬ê¸°
            msgs = []
            for m in raw_msgs:
                m_type = m.get("type", "")
                if m_type in ["ai", "ai_message", "tool", "tool_message"]:
                    if m_type == "ai_message": m["type"] = "ai"
                    if m_type == "tool_message": m["type"] = "tool"
                    msgs.append(m)

            def clean_think(text):
                if not text: return ""
                text = re.sub(r"<think>", "", text)
                text = re.sub(r"</think>", "", text)
                return text.strip()

            clean_final = clean_think(str(response_content)).strip()
            
            sys_content = "You are Biomni-R0, an advanced reasoning and acting agent. Use <think>...</think> tags to show your step-by-step reasoning process before acting. Use <execute> to run python code and gather data. Use <solution> to provide the final answer."
            
            system_msg = dump_msg(SystemMessage(content=sys_content))
            human_msg = dump_msg(HumanMessage(content=request.message))
            
            messages = [system_msg, human_msg]
            seen_contents = set()
            
            # ì—¬ê¸°ì„œë¶€í„° ì˜¬ë ¤ì£¼ì‹  "id", "tool_calls" ë“±ì˜ ê¸´ í˜•ì‹ ê·¸ëŒ€ë¡œ ìˆ˜ì‹­ ê°œì˜ ê³¼ì •ì´ ë“¤ì–´ê°‘ë‹ˆë‹¤.
            for m in msgs:
                m_copy = dict(m) 
                m_type = m_copy.get("type")
                content = str(m_copy.get("content", "") or "")
                
                clean_content = clean_think(content)
                
                if m_type == "tool":
                    m_copy["content"] = clean_content
                    messages.append(m_copy)
                    continue
                    
                if m_type == "ai":
                    # ì¤‘ë³µ ë‹µë³€ ì°¨ë‹¨ (next_step: end ë°”ë¡œ ìœ„ì˜ ë™ì¼ ë‹µë³€ ì‚­ì œ)
                    if clean_content and clean_content in seen_contents:
                        continue
                        
                    if clean_content:
                        seen_contents.add(clean_content)
                        
                    # ìµœì¢… ë‹µë³€(final_answer)ê³¼ ì™„ì „íˆ ë™ì¼í•œ ê²½ìš° thinkë¡œ ê°ì‹¸ì§€ ì•ŠìŒ
                    if clean_content == clean_final:
                        m_copy["content"] = clean_content
                    else:
                        # ì¤‘ê°„ ì¶”ë¡  ê³¼ì •ì€ ë‚´ìš©ì´ ìˆì„ ê²½ìš° ì „ì²´ë¥¼ <think>ë¡œ ê°ì‹¸ê¸°
                        if clean_content.strip():
                            m_copy["content"] = f"<think>\n{clean_content}\n</think>"
                        else:
                            m_copy["content"] = ""
                            
                    messages.append(m_copy)

            refined_data = {
                "trace_id": trace_id,
                "messages": messages
            }
            
            refined_file_path = os.path.join(refined_dir, f"trace_{trace_id}.json")
            with open(refined_file_path, "w", encoding="utf-8") as f:
                json.dump(refined_data, f, ensure_ascii=False, indent=4)
                
            logger.info(f"âœ… Saved raw and refined trace data to {base_log_dir} (Trace ID: {trace_id})")

        # 5. [ìˆ˜ì •ë¨] ë¡œê·¸ë¥¼ í¬í•¨í•˜ì—¬ ë°˜í™˜
        return {
            "response": str(response_content),
            "logs": response_log # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì¤‘ê°„ ê³¼ì •ì„ ì‹œê°í™”í•˜ê¸° ìœ„í•´ í•„ìˆ˜
        }
    
    except Exception as e:
        logger.error(f"Error during execution: {e}")
        langfuse_context.update_current_trace(level="ERROR", status_message=str(e))
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    # app ëŒ€ì‹  "main:app" ë¬¸ìì—´ë¡œ ë„£ê³ , reload=Trueë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)