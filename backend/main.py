import os
import sys
import logging
import json
import uuid
import time
import requests
from datetime import datetime
from typing import Optional, List, Any, Dict
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from dotenv import load_dotenv

# [ë¡œì»¬ ê°œë°œìš©] ìƒìœ„ í´ë”(.env)ì˜ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
# Dockerì—ì„œëŠ” env_fileë¡œ ì£¼ì…ë˜ì§€ë§Œ, ë¡œì»¬ ì‹¤í–‰ ì‹œ í•„ìš”í•©ë‹ˆë‹¤.
load_dotenv(dotenv_path="../.env")

# --- [Monkey Patching: í˜¸í™˜ì„± í•´ê²°] ---
import langchain_core.callbacks
import langchain_core.callbacks.base
import langchain_core.agents
import langchain_core.documents
import langchain_core.messages
import langchain_core.outputs

sys.modules["langchain.callbacks"] = langchain_core.callbacks
sys.modules["langchain.callbacks.base"] = langchain_core.callbacks.base
sys.modules["langchain.schema"] = langchain_core.messages 
sys.modules["langchain.schema.agent"] = langchain_core.agents
sys.modules["langchain.schema.document"] = langchain_core.documents

# [Langfuse & LangChain Integrations]
from langfuse.decorators import observe, langfuse_context
from langfuse.callback import CallbackHandler

# --- [Biomni Import] ---
from biomni.agent.a1 import A1

load_dotenv(dotenv_path="../.env")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("BiomniWeb")

app = FastAPI()

# 1. ì •ì  íŒŒì¼ ì„œë¹™ ì¶”ê°€ (ìƒì„±ëœ ì´ë¯¸ì§€/PDF ì ‘ê·¼ìš©)
# Docker volume ë§¤í•‘ì— ë§ì¶° ê²½ë¡œ ì„¤ì • (ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ê²½ë¡œ: /app/data)
if os.path.exists("/app/data"):
    app.mount("/data", StaticFiles(directory="/app/data"), name="data")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

agent: Optional[A1] = None

def initialize_agent():
    global agent
    logger.info("Initializing Biomni Agent...")
    try:
        # Docker í™˜ê²½ ë³€ìˆ˜ ìš°ì„ , ì—†ìœ¼ë©´ ë¡œì»¬ ê²½ë¡œ
        data_path = os.getenv("BIOMNI_DATA_PATH", "../biomni_data")
        agent = A1(path=data_path)
        logger.info("Biomni Agent initialized successfully.")
    except Exception as e:
        logger.error(f"Failed to initialize Biomni Agent: {e}")
        agent = None

initialize_agent()

class ChatRequest(BaseModel):
    message: str

# ì‘ë‹µ ëª¨ë¸ ì •ì˜ (ë¡œê·¸ í¬í•¨)
class ChatResponse(BaseModel):
    response: str
    logs: List[Any]  # Biomniì˜ response_log êµ¬ì¡°ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ì„¤ì •

@app.post("/api/chat", response_model=ChatResponse)
@observe(name="Biomni Chat Interaction")
async def chat_endpoint(request: ChatRequest):
    if not agent:
        # ì¬ì‹œë„ ë¡œì§ (í•„ìš”ì‹œ)
        initialize_agent()
        if not agent:
            raise HTTPException(status_code=500, detail="Agent not initialized")
    
    logger.info(f"Received request: {request.message}")
    
    try:
        # ... (ê¸°ì¡´ Monkey Patching ë¡œì§ ê·¸ëŒ€ë¡œ ìœ ì§€) ...
        # (original_stream, traced_stream ì •ì˜ ë¶€ë¶„)

        # agent.app.stream = traced_stream 
        
        # 4. ì—ì´ì „íŠ¸ ì‹¤í–‰
        langfuse_handler = langfuse_context.get_current_langchain_handler()
        response_log, response_content = agent.go(request.message, callbacks=[langfuse_handler])
        
        # agent.app.stream = original_stream
        
        # Langfuse ì—…ë°ì´íŠ¸
        langfuse_context.update_current_trace(
            output=str(response_content),
            metadata={"full_log_length": len(response_log)}
        )

        # ğŸŒŸ ë§¤ìš° ì¤‘ìš”: ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìˆ˜ì§‘ ì¤‘ì¸ ëª¨ë“  í•˜ìœ„ Spanë“¤ì„ ì„œë²„ë¡œ ê°•ì œ ì „ì†¡ ì™„ë£Œì‹œí‚µë‹ˆë‹¤.
        langfuse_context.flush()

        trace_id = langfuse_context.get_current_trace_id()
        
        # Langfuse ì„œë²„ì˜ DBì— í•˜ìœ„ Spanë“¤ì´ ì™„ì „íˆ ê¸°ë¡ë  ë•Œê¹Œì§€ ì•„ì£¼ ì ê¹(1~2ì´ˆ) ëŒ€ê¸°í•©ë‹ˆë‹¤.
        time.sleep(1.5) 
        
        langfuse_host = os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com").rstrip("/")
        public_key = os.getenv("LANGFUSE_PUBLIC_KEY")
        secret_key = os.getenv("LANGFUSE_SECRET_KEY")
        
        # Langfuse REST APIë¥¼ í˜¸ì¶œí•˜ì—¬ í•´ë‹¹ íŠ¸ë ˆì´ìŠ¤ì˜ 'ëª¨ë“  ì„¸ë¶€ ì •ë³´'ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤.
        api_url = f"{langfuse_host}/api/public/traces/{trace_id}"
        api_response = requests.get(api_url, auth=(public_key, secret_key))
        
        if api_response.status_code == 200:
            full_trace_data = api_response.json()
            
            # full_trace_data ì•ˆì—ëŠ” "observations"ë¼ëŠ” ë°°ì—´ì´ ìˆìœ¼ë©°, 
            # ì—¬ê¸°ì— LLM í˜¸ì¶œ, Tool ê²€ìƒ‰, ì½”ë“œ ì‹¤í–‰ ë“± ëª¨ë“  í•˜ìœ„ spanì´ ë“¤ì–´ìˆìŠµë‹ˆë‹¤.
            base_log_dir = "/app/logs" # ë˜ëŠ” "/app/data/reasoning_dataset"
            
            # ==============================================================
            # 1. ì›ë³¸ ë°ì´í„° (Raw Data) ì „ìš© í´ë” ë° ì €ì¥
            # ==============================================================
            raw_dir = os.path.join(base_log_dir, "raw")
            os.makedirs(raw_dir, exist_ok=True)
            
            raw_data = {
                "trace_id": trace_id,
                "timestamp": datetime.now().isoformat(),
                "instruction": request.message,
                "langfuse_full_trace": full_trace_data, 
                "final_answer": str(response_content)
            }
            
            # íŒŒì¼ëª…ì€ ê¹”ë”í•˜ê²Œ í†µì¼
            raw_file_path = os.path.join(raw_dir, f"trace_{trace_id}.json")
            with open(raw_file_path, "w", encoding="utf-8") as f:
                json.dump(raw_data, f, ensure_ascii=False, indent=4)
                
            # ==============================================================
            # 2. íŒŒì¸íŠœë‹ìš© ì •ì œ ë°ì´í„° (Agent Training Format - ChatML/ShareGPT)
            # ==============================================================
            refined_dir = os.path.join(base_log_dir, "refined")
            os.makedirs(refined_dir, exist_ok=True)
            
            observations = full_trace_data.get("observations", [])
            observations.sort(key=lambda x: x.get("startTime", ""))
            
            # í•™ìŠµ í‘œì¤€ í¬ë§·ì¸ messages ë°°ì—´ ìƒì„±
            messages = [
                {"role": "system", "content": "You are Biomni-R0, an advanced reasoning and acting agent. Use <execute> to run python code and gather data. Use <solution> to provide the final answer."},
                {"role": "user", "content": request.message}
            ]
            
            for obs in observations:
                obs_type = obs.get("type")
                name = obs.get("name", "")
                output = obs.get("output")
                
                if not output:
                    continue
                
                output_text = str(output)
                if isinstance(output, dict) and "content" in output:
                    output_text = str(output["content"])
                
                # 1. ëª¨ë¸ì´ ì§ì ‘ ìƒì„±í•œ í…ìŠ¤íŠ¸ (ìƒê° + <execute> ë˜ëŠ” <solution>)
                if obs_type == "GENERATION":
                    # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ assistantê°€ ì•„ë‹ ë•Œë§Œ ì¶”ê°€
                    if messages[-1]["role"] != "assistant":
                        messages.append({"role": "assistant", "content": output_text.strip()})
                
                # 2. íŒŒì´ì¬ ìƒŒë“œë°•ìŠ¤ê°€ ì‹¤í–‰í•œ ê²°ê³¼ (Observation)
                elif obs_type == "SPAN" and ("Run" in name or "Tool" in name or "execute" in name.lower()):
                    messages.append({
                        "role": "tool",  # í”„ë ˆì„ì›Œí¬ì— ë”°ë¼ "user" ë˜ëŠ” "observation"ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥
                        "content": f"Observation:\n{output_text.strip()}"
                    })

            refined_data = {
                "trace_id": trace_id,
                "messages": messages
            }
            
            refined_file_path = os.path.join(refined_dir, f"trace_{trace_id}.json")
            with open(refined_file_path, "w", encoding="utf-8") as f:
                json.dump(refined_data, f, ensure_ascii=False, indent=4)
                
            logger.info(f"âœ… Saved trace data to {raw_dir} and {refined_dir}")
        else:
            logger.error(f"Failed to fetch trace from Langfuse: {api_response.text}")

        # 5. [ìˆ˜ì •ë¨] ë¡œê·¸ë¥¼ í¬í•¨í•˜ì—¬ ë°˜í™˜
        return {
            "response": str(response_content),
            "logs": response_log # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì¤‘ê°„ ê³¼ì •ì„ ì‹œê°í™”í•˜ê¸° ìœ„í•´ í•„ìˆ˜
        }
    
    except Exception as e:
        logger.error(f"Error during execution: {e}")
        langfuse_context.update_current_trace(level="ERROR", status_message=str(e))
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    # app ëŒ€ì‹  "main:app" ë¬¸ìì—´ë¡œ ë„£ê³ , reload=Trueë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)